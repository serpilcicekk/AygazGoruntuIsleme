{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2333429,"sourceType":"datasetVersion","datasetId":1408532}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Aygaz Görüntü İşleme Bootcamp Projesi Proje Amacı**\n\nBu projede, görüntü işleme ve derin öğrenme teknikleri kullanılarak 10 farklı hayvan türünün sınıflandırılması hedeflenmiştir. Modelin dayanıklılığı, manipüle edilmiş test setleri ve renk sabitliği algoritmalarıyla test edilmiştir.","metadata":{}},{"cell_type":"markdown","source":"**1. Veri Setini Kullanma ve Dinamik Toplama**\n\nVeri seti, Animals with Attributes 2 (AwA2) klasör yapısına sahiptir.\nHer alt klasör bir sınıfı temsil eder.\nDinamik bir yapı ile tüm görseller ve sınıf etiketleri toplanır.\n","metadata":{}},{"cell_type":"code","source":"import os\n\n# Veri setinin ana klasörü\nDATASET_DIR = \"/kaggle/input/animals-with-attributes-2/Animals_with_Attributes2/JPEGImages\"\n\n\n# Projede kullanılacak sınıflar\nselected_classes = [\"collie\", \"dolphin\", \"elephant\", \"fox\", \"moose\", \n                    \"rabbit\", \"sheep\", \"squirrel\", \"giant+panda\", \"polar+bear\"]\n\n# Mevcut sınıfları kontrol et\navailable_classes = [cls for cls in os.listdir(DATASET_DIR) if os.path.isdir(os.path.join(DATASET_DIR, cls))]\n\nprint(f\"Veri setinde toplam {len(available_classes)} sınıf bulunuyor.\")\nprint(f\"Mevcut sınıflar: {available_classes}\")\n\n# Seçilen sınıfların mevcut olup olmadığını doğrula\nmissing_classes = [cls for cls in selected_classes if cls not in available_classes]\nif missing_classes:\n    print(f\"Uyarı: Aşağıdaki sınıflar veri setinde bulunamadı: {missing_classes}\")\nelse:\n    print(f\"Tüm seçilen sınıflar mevcut: {selected_classes}\")\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:51:40.720683Z","iopub.execute_input":"2024-12-22T15:51:40.720991Z","iopub.status.idle":"2024-12-22T15:51:40.728691Z","shell.execute_reply.started":"2024-12-22T15:51:40.720962Z","shell.execute_reply":"2024-12-22T15:51:40.728019Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**2. Görsellerin Yüklenmesi ve İşlenmesi**\n\n* Görseller, 128x128 piksel boyutuna küçültülür.\n* Görseller 0-1 aralığında normalize edilir.\n* Her sınıftan maksimum 650 görsel alınır.","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\n\n# 1. Veri Seti ve Sınıf Parametreleri\nDATASET_DIR =\"/kaggle/input/animals-with-attributes-2/Animals_with_Attributes2/JPEGImages\"\nselected_classes = [\"collie\", \"dolphin\", \"elephant\", \"fox\", \"moose\", \n                    \"rabbit\", \"sheep\", \"squirrel\", \"giant+panda\", \"polar+bear\"]\n\nIMAGE_SIZE = (128, 128)\nMAX_IMAGES_PER_CLASS = 650\n\ndef prepare_images(dataset_dir, selected_classes, image_size, max_images_per_class):\n    images, labels = [], []\n    for class_name in selected_classes:\n        class_path = os.path.join(dataset_dir, class_name)\n        image_files = os.listdir(class_path)[:max_images_per_class]\n        for img_name in image_files:\n            img_path = os.path.join(class_path, img_name)\n            img = cv2.imread(img_path)\n            if img is not None:\n                img_resized = cv2.resize(img, image_size)\n                images.append(img_resized / 255.0)  # Normalizasyon\n                labels.append(class_name)\n    return np.array(images), np.array(labels)\n\nX, y = prepare_images(DATASET_DIR, selected_classes, IMAGE_SIZE, MAX_IMAGES_PER_CLASS)\nprint(f\"Toplam Görsel: {X.shape[0]}, Sınıflar: {np.unique(y)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:47:19.045136Z","iopub.execute_input":"2024-12-22T15:47:19.045532Z","iopub.status.idle":"2024-12-22T15:49:31.748361Z","shell.execute_reply.started":"2024-12-22T15:47:19.045497Z","shell.execute_reply":"2024-12-22T15:49:31.747389Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**3. Eğitim ve Test Setinin Ayrılması**\n\n* Veriler %70 eğitim ve %30 test olarak ayrılmıştır.\n* Etiketler, LabelEncoder ile sayısal değerlere çevrilmiş ve ardından one-hot encoding uygulanmıştır.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.utils import to_categorical\n\n# Etiketleri dijital değerlere dönüştürme\nencoder = LabelEncoder()\ny_encoded = encoder.fit_transform(y)  # y, 2. adımda tanımlanan etiketlerdir\n\n# One-hot encoding\ny_categorical = to_categorical(y_encoded)\n\n# Eğitim ve test setine ayırma (%70 eğitim, %30 test)\nX_train, X_test, y_train, y_test = train_test_split(X, y_categorical, test_size=0.3, random_state=42)\n\n# Çıktı boyutlarını yazdırma\nprint(f\"Eğitim veri boyutu: {X_train.shape}, Test veri boyutu: {X_test.shape}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T15:55:38.701828Z","iopub.execute_input":"2024-12-22T15:55:38.702129Z","iopub.status.idle":"2024-12-22T15:55:39.377330Z","shell.execute_reply.started":"2024-12-22T15:55:38.702105Z","shell.execute_reply":"2024-12-22T15:55:39.376427Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**4. Veri Artırımı (Augmentation)**\n\n* Eğitim verisi üzerinde veri artırma yöntemleri uygulanmıştır.\n\nAşağıdaki işlemler gerçekleştirilmiştir:\n\nDöndürme (20 dereceye kadar)\n\nYakınlaştırma/Uzaklaştırma (%20)\n\nYatay eksende ayna yansıması\n\nYatay ve dikey kaydırma","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator(\n    rotation_range=20,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    width_shift_range=0.15,\n    height_shift_range=0.15,\n    shear_range=0.2\n)\ndatagen.fit(X_train)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T17:30:47.476687Z","iopub.execute_input":"2024-12-22T17:30:47.476972Z","iopub.status.idle":"2024-12-22T17:30:48.128920Z","shell.execute_reply.started":"2024-12-22T17:30:47.476949Z","shell.execute_reply":"2024-12-22T17:30:48.128250Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**5. CNN Modelinin Tasarlanması**\n\nModelde kullanılan katmanlar:\n* Conv2D: Görüntüden özellik çıkarma.\n* MaxPooling2D: Önemli bilgileri seçme.\n* Flatten: Matrisleri vektör haline getirme.\n* Dense: Tam bağlantılı katmanlar.\n* Dropout: Ezberlemeyi önleme.","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n\nmodel = Sequential([\n    Input(shape=(128, 128, 3)),\n    Conv2D(32, (3, 3), activation='relu'),\n    MaxPooling2D((2, 2)),\n    Conv2D(64, (3, 3), activation='relu'),\n    MaxPooling2D((2, 2)),\n    Flatten(),\n    Dense(128, activation='relu'),\n    Dropout(0.5),\n    Dense(10, activation='softmax')\n])\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T17:30:54.156816Z","iopub.execute_input":"2024-12-22T17:30:54.157115Z","iopub.status.idle":"2024-12-22T17:30:54.221570Z","shell.execute_reply.started":"2024-12-22T17:30:54.157090Z","shell.execute_reply":"2024-12-22T17:30:54.220750Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**6. Modelin Eğitilmesi ve Test Edilmesi**\n\n* Model 30 epoch boyunca eğitilmiştir.\n* Eğitim ve doğrulama setindeki doğruluk oranları hesaplanmıştır.\n\n","metadata":{}},{"cell_type":"code","source":"history = model.fit(\n    datagen.flow(X_train, y_train, batch_size=32),\n    validation_data=(X_test, y_test),\n    epochs=30\n)\n\ntest_loss, test_acc = model.evaluate(X_test, y_test)\nprint(f\"Test doğruluğu: {test_acc * 100:.2f}%\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T17:31:01.741155Z","iopub.execute_input":"2024-12-22T17:31:01.741510Z","iopub.status.idle":"2024-12-22T17:38:42.166750Z","shell.execute_reply.started":"2024-12-22T17:31:01.741473Z","shell.execute_reply":"2024-12-22T17:38:42.165971Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**7. Manipüle Edilmiş Görüntülerle Test**\n\nGörseller manipüle edilmiştir:\n\nKontrast artırma.\n\nSaat yönünde döndürme.\n\nModelin dayanıklılığı ölçülmüştür.","metadata":{}},{"cell_type":"code","source":"def manipulate_images(images):\n    manipulated_images = []\n    for img in images:\n        bright = cv2.convertScaleAbs(img, alpha=1.5, beta=20)  # Kontrast artırma\n        rotated = cv2.rotate(bright, cv2.ROTATE_90_CLOCKWISE)\n        manipulated_images.append(rotated)\n    return np.array(manipulated_images)\n\nX_test_manipulated = manipulate_images(X_test)\nmanipulated_loss, manipulated_acc = model.evaluate(X_test_manipulated, y_test)\nprint(f\"Manipüle edilmiş doğruluk: {manipulated_acc * 100:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T17:43:28.514318Z","iopub.execute_input":"2024-12-22T17:43:28.514701Z","iopub.status.idle":"2024-12-22T17:43:29.612837Z","shell.execute_reply.started":"2024-12-22T17:43:28.514670Z","shell.execute_reply":"2024-12-22T17:43:29.611962Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**8. Renk Sabitliği Algoritması**\n\nGörsellere renk sabitliği algoritması uygulanarak normalize edilmiştir.\n\n\"Gray World Assumption\" yöntemi kullanılmıştır","metadata":{}},{"cell_type":"code","source":"def apply_color_constancy(images):\n    processed_images = []\n    for img in images:\n        avg_channels = np.mean(img, axis=(0, 1))\n        avg_intensity = np.mean(avg_channels)\n        scale = avg_intensity / avg_channels\n        balanced = img * scale.reshape(1, 1, -1)\n        processed_images.append(np.clip(balanced, 0, 1))\n    return np.array(processed_images)\n\nX_test_color_const = apply_color_constancy(X_test)\ncolor_loss, color_acc = model.evaluate(X_test_color_const, y_test)\nprint(f\"Renk sabitliği doğruluğu: {color_acc * 100:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T17:46:46.620851Z","iopub.execute_input":"2024-12-22T17:46:46.621199Z","iopub.status.idle":"2024-12-22T17:46:49.209822Z","shell.execute_reply.started":"2024-12-22T17:46:46.621170Z","shell.execute_reply":"2024-12-22T17:46:49.209097Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**9. Sonuçların Karşılaştırılması ve Raporlama**\n\nOrijinal, manipüle edilmiş ve renk sabitliği uygulanmış görüntülerin doğruluk oranları görselleştirilmiştir.","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\naccuracies = [test_acc * 100, manipulated_acc * 100, color_acc * 100]\nlabels = ['Orijinal', 'Manipüle', 'Renk Sabitliği']\nplt.bar(labels, accuracies, color=['blue', 'orange', 'green'])\nplt.ylabel('Doğruluk (%)')\nplt.title('Performans Karşılaştırması')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T17:48:33.328936Z","iopub.execute_input":"2024-12-22T17:48:33.329270Z","iopub.status.idle":"2024-12-22T17:48:33.486018Z","shell.execute_reply.started":"2024-12-22T17:48:33.329245Z","shell.execute_reply":"2024-12-22T17:48:33.485120Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Test sonuçlarının karşılaştırılması ve çıktılar\nprint(\"Sonuçlar:\")\n\n# Orijinal test seti doğruluğunu yazdır\nprint(f\"Orijinal Test Seti Doğruluğu: {test_acc * 100:.2f}%\")\n\n# Manipüle edilmiş test seti doğruluğunu yazdır\nprint(f\"Manipüle Edilmiş Test Seti Doğruluğu: {manipulated_acc * 100:.2f}%\")\n\n# Renk sabitliği uygulanmış test seti doğruluğunu yazdır\nprint(f\"Renk Sabitliği Uygulanmış Test Seti Doğruluğu: {color_acc * 100:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-22T18:04:54.216485Z","iopub.execute_input":"2024-12-22T18:04:54.216804Z","iopub.status.idle":"2024-12-22T18:04:54.222453Z","shell.execute_reply.started":"2024-12-22T18:04:54.216779Z","shell.execute_reply":"2024-12-22T18:04:54.221504Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Sonuç ve Çözüm Önerileri**\n* Manipüle Edilmiş Görseller: Modelin manipüle edilmiş görsellerde performansı oldukça düşüktür. Eğitim sürecine manipüle edilmiş veri dahil edilerek bu performans artırılabilir.\n* Renk Sabitliği: Renk sabitliği algoritması, manipüle edilmiş görseller üzerinde modelin doğruluğunu önemli ölçüde artırmıştır.\n* Sonuç: Model, orijinal test setinde %67.64 doğrulukla temel bir başarı sergilemiştir. Performansı artırmak için daha karmaşık model mimarileri veya veri artırma teknikleri kullanılabilir.","metadata":{}}]}